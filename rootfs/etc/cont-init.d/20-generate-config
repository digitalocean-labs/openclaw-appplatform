#!/command/with-contenv bash
# Generate moltbot gateway configuration

set -e

# Ensure state directory exists with correct ownership
mkdir -p "$MOLTBOT_STATE_DIR"
chown moltbot:moltbot "$MOLTBOT_STATE_DIR"

DEFAULT_CONFIG="/etc/moltbot/moltbot.default.json"
CONFIG_FILE="$MOLTBOT_STATE_DIR/moltbot.json"

echo "[generate-config] Building config: $CONFIG_FILE"

# Show version
echo "[generate-config] Moltbot version: $(moltbot --version 2>/dev/null || echo 'unknown')"

# Generate a gateway token if not provided
if [ -z "$MOLTBOT_GATEWAY_TOKEN" ]; then
  export MOLTBOT_GATEWAY_TOKEN=$(head -c 32 /dev/urandom | base64 | tr -d '=/+' | head -c 32)
  echo "[generate-config] Generated gateway token (ephemeral)"
  # Write to s6 environment so services can access it
  mkdir -p /run/s6/container_environment
  echo "$MOLTBOT_GATEWAY_TOKEN" > /run/s6/container_environment/MOLTBOT_GATEWAY_TOKEN
fi

# Start with default config as base
if [ -f "$DEFAULT_CONFIG" ]; then
  cp "$DEFAULT_CONFIG" "$CONFIG_FILE"
  echo "[generate-config] Using default config from $DEFAULT_CONFIG"
else
  # Fallback minimal config if default doesn't exist
  echo '{"gateway": {"mode": "local"}}' > "$CONFIG_FILE"
  echo "[generate-config] Warning: Default config not found, using minimal config"
fi

# Add Gradient AI provider if API key is set
if [ -n "$GRADIENT_API_KEY" ]; then
  echo "[generate-config] Adding Gradient AI provider to config"
  GRADIENT_CONFIG=$(cat << 'GRADIENTEOF'
{
  "models": {
    "mode": "merge",
    "providers": {
      "gradient": {
        "baseUrl": "https://inference.do-ai.run/v1",
        "api": "openai-completions",
        "models": [
          {
            "id": "llama3.3-70b-instruct",
            "name": "Llama 3.3 70B Instruct",
            "reasoning": false,
            "input": ["text"],
            "contextWindow": 128000,
            "maxTokens": 8192
          },
          {
            "id": "anthropic-claude-4.5-sonnet",
            "name": "Claude 4.5 Sonnet",
            "reasoning": false,
            "input": ["text"],
            "contextWindow": 200000,
            "maxTokens": 8192
          },
          {
            "id": "anthropic-claude-opus-4.5",
            "name": "Claude Opus 4.5",
            "reasoning": true,
            "input": ["text"],
            "contextWindow": 200000,
            "maxTokens": 16384
          },
          {
            "id": "deepseek-r1-distill-llama-70b",
            "name": "DeepSeek R1 Distill Llama 70B",
            "reasoning": true,
            "input": ["text"],
            "contextWindow": 128000,
            "maxTokens": 8192
          }
        ]
      }
    }
  },
  "agents": {
    "defaults": {
      "model": {
        "primary": "gradient/llama3.3-70b-instruct"
      }
    }
  }
}
GRADIENTEOF
)
  # Merge Gradient config into main config, injecting the API key
  jq --argjson gradient "$GRADIENT_CONFIG" \
     --arg apiKey "$GRADIENT_API_KEY" \
     '. * $gradient | .models.providers.gradient.apiKey = $apiKey' \
     "$CONFIG_FILE" > "${CONFIG_FILE}.tmp" && mv "${CONFIG_FILE}.tmp" "$CONFIG_FILE"
fi

# Ensure moltbot owns all state files
chown -R moltbot:moltbot "$MOLTBOT_STATE_DIR"

echo "[generate-config] Final config:"
jq '.' "$CONFIG_FILE"
